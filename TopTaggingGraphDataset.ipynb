{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754f54fd-84b1-4f6f-a933-9abfb6967d68",
   "metadata": {},
   "source": [
    "**Note:** This notebook needs the `awkward` and `vector` packages. You can install them with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade01d6-d77a-4d16-afc0-8dfae80c9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install awkward vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db02faa-b70d-45cc-a8e2-d58763d9e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import awkward as ak\n",
    "import vector\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd20c73c-ea75-4dc2-801e-b42f772e6d57",
   "metadata": {},
   "source": [
    "The dataset is the same as in [`CNNTopTaggingPreprocessing.ipynb`](CNNTopTaggingPreprocessing.ipynb) and you can download it from https://desycloud.desy.de/index.php/s/llbX3zpLhazgPJ6 (1.6 GB) (see [arXiv:1707.08966](https://arxiv.org/abs/1707.08966))\n",
    "\n",
    "Here we are going to preprocess the dataset such that we get an adjacency matrix of the 7 nearest neighbors and the coordinates $p_\\mathrm{T}, \\eta, \\phi, E$ relativ to the center of mass of the jet. \n",
    "\n",
    "Adjust the following path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b122f5b7-acb5-4993-b2e4-c8d357910ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./top_tagging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af5b60-2872-4252-a2fe-96102355dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(data_path / \"train.h5\", \"table\", stop=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d3a626-1f08-4086-8694-7869b6173676",
   "metadata": {},
   "source": [
    "First load the list of up to 200 particles into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e82218-f2dd-4a31-87a4-b3c315206f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_4mom = df.loc[:, :\"PZ_199\"].to_numpy().reshape(-1, 200, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05d51a-9aca-4c3a-b9fa-29d285f6d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_4mom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2568d8-bcf2-4870-aee1-8aed90040efc",
   "metadata": {},
   "source": [
    "Next, we need to convert this to an awkward vector to be able to to LorentzVector arithmetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd0bb7-298c-4c30-9351-a4330bd2c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ak_vec(jet_4mom):\n",
    "    p4 = ak.from_regular(vector.zip({key: jet_4mom[..., i] for i, key in enumerate([\"e\", \"px\", \"py\", \"pz\"])}))\n",
    "    return p4[~((p4.e == 0) & (p4.px == 0) & (p4.py == 0) & (p4.pz == 0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c96fc3-1d5a-4b00-9dcd-1da4ede7d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p4 = to_ak_vec(jet_4mom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4aa67ee-a7c9-4650-b8c6-7e91012dda68",
   "metadata": {},
   "source": [
    "This will now have a variable length of jet constituents for each event:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9685e2ca-10ef-46d1-8d10-a470b085031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e9a3fe-0c11-4c34-beb6-11ea69ae1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.num(p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6668dc-8797-4e14-afbd-48f890ab1412",
   "metadata": {},
   "source": [
    "Since we want to have the coordinates relative to the center of mass, we need to sum the constituents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d622ff3-0238-4f97-a2f0-9d23f21b50e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_sum(p4):\n",
    "    # sum not yet working with vector without converting again https://github.com/scikit-hep/vector/issues/92\n",
    "    p4_sum = ak.sum(p4, axis=-1)\n",
    "    return vector.zip({k1: p4_sum[k2] for k1, k2 in [(\"px\", \"x\"), (\"py\", \"y\"), (\"pz\", \"z\"), (\"e\", \"t\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e72349-67b0-472e-b1d7-c63ef7eadb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_sum(p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1c7ce6-cf29-4881-82b6-c2739b85fdbe",
   "metadata": {},
   "source": [
    "We will scale the transverse momentum and energy relative to the total sum and the eta and phi relative to the center of mass. Furthermore we will pad and clip the array to up to 100 particles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0890ae12-97f5-45fd-bd64-1f4ae062f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_for_traindata(p4, npad=100):\n",
    "    p4_sum = vec_sum(p4)\n",
    "    p4_train = ak.concatenate(\n",
    "        [\n",
    "            _p[..., np.newaxis] for _p in [\n",
    "                p4.pt / p4_sum.pt,\n",
    "                p4.deltaeta(p4_sum),\n",
    "                p4.deltaphi(p4_sum),\n",
    "                p4.e / p4_sum.e\n",
    "            ]\n",
    "        ],\n",
    "        axis=-1\n",
    "    )\n",
    "    return ak.fill_none(ak.pad_none(p4_train, npad, axis=1, clip=True), [0, 0, 0, 0], axis=-2).to_numpy().astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ce3e0-9ccf-46f4-b16d-1e592d80e642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_for_traindata(p4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81378bf5-d1ec-44c4-9208-9ec2fc7503a6",
   "metadata": {},
   "source": [
    "For the adjacency matrix we need to look at the distance in the $\\eta-\\phi$ plane (`deltaR`) for each pair (using `ak.cartesian`) of jet constituents and get the top-$K$ indices that sort these distances for each constituent (using `ak.argsort`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100fd6f8-b6ca-40c3-9f29-5b46b9869806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_indices(array, K, chunksize=1000):\n",
    "    out = []\n",
    "    for start in tqdm(range(0, len(array), chunksize)):\n",
    "        # do this in chunks to save memory\n",
    "        chunk = array[start: start + chunksize]\n",
    "        p1, p2 = ak.unzip(ak.cartesian([chunk, chunk], axis=-1, nested=True))\n",
    "        i1, i2 = ak.unzip(ak.argcartesian([chunk, chunk], nested=True))\n",
    "        p1, p2 = [p[i1 != i2] for p in [p1, p2]] # exclude self\n",
    "        dr = p1.deltaR(p2)\n",
    "        out.append(ak.values_astype(ak.argsort(dr)[..., :K], np.uint8))\n",
    "    return ak.concatenate(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149e5e2a-2754-4e66-b39f-769d875a6a98",
   "metadata": {},
   "source": [
    "This will be fastest when we convert the vector into $p_\\mathrm{T}, \\phi, \\eta$ coordinates beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baebf7b8-9cf9-4b73-8a6e-2cba7d8c218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_indices = get_knn_indices(p4.to_rhophieta(), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b804e5-b6be-4e9a-8141-b01b86ca660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_indices[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b68e4e7-d5a5-40c7-b974-572a27152577",
   "metadata": {},
   "source": [
    "We need to convert this into 0-padded adjacency matrices for up to 100 particles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fca1f2-29fd-4dcf-99d7-3669c9a945eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_adjacency(nn_indices, npad=100):\n",
    "    nn_indices = nn_indices[nn_indices < npad][:, :npad] # clip at 100 particles\n",
    "    # add self loops\n",
    "    nn_indices = ak.concatenate([ak.local_index(nn_indices, axis=1)[..., np.newaxis], nn_indices], axis=2)\n",
    "    # find the indices where the adjacency matrices should be 1\n",
    "    ii, jj, kk = ak.unzip(ak.zip([ak.local_index(nn_indices, axis=0), ak.local_index(nn_indices, axis=1), nn_indices]))\n",
    "    ii, jj, kk = [ak.flatten(x, axis=None).to_numpy() for x in [ii, jj, kk]]\n",
    "    # create and fill the adjacency matrices\n",
    "    m = np.zeros((len(nn_indices), npad, npad), dtype=np.uint8)\n",
    "    m[ii, jj, kk] = 1\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624604f8-bde5-49c0-b0eb-31ba1f3ecd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = to_adjacency(knn_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c04103-47e5-4078-b8d0-e7fb54dde776",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(adj[10], cmap=\"Greys_r\", interpolation=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8279503f-6df0-4808-a821-3a8a53e93c7e",
   "metadata": {},
   "source": [
    "Now, store everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c62d5-91cd-45bc-91b5-45b6f7973e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1ee1f0-1391-4040-ae15-68923c9030bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path, nexamples, npad=100, K=7):\n",
    "    df = pd.read_hdf(path, \"table\", stop=nexamples)\n",
    "    p4 = to_ak_vec(df.loc[:, :\"PZ_199\"].to_numpy().reshape(-1, 200, 4))\n",
    "    x = transform_for_traindata(p4, npad=npad)\n",
    "    y = df[\"is_signal_new\"].to_numpy().astype(bool)\n",
    "    adj = to_adjacency(get_knn_indices(p4.to_rhophieta(), K), npad=npad)\n",
    "    return x, adj, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f95f6-e396-4d9e-b4b6-93329f715e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, adj, y = preprocess(data_path / \"train.h5\", 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdbdb74-02bc-4c50-a0e0-ceb8c1117c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"top_tagging_100k.npz\", x=x, adj=adj, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbca7ed-69bd-49e6-8ec2-6173b665d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah top_tagging_100k.npz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}