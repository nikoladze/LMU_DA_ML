{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for `CNNTopTagging.ipynb` (optional excercise)\n",
    "\n",
    "The dataset used in [`CNNTopTagging.ipynb`](CNNTopTagging.ipynb) has to be preprocessed to be in the form of images. Preprocessed images for 100k training and testing examples and 10k validation examples are provided in the [data](data) folder of the course repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## The dataset\n",
    "\n",
    "The authors of [arXiv:1707.08966](https://arxiv.org/abs/1707.08966) provide us with a dataset for studying this problem. There is also a [summary paper](https://arxiv.org/abs/1902.09914) reviewing different methods.\n",
    "\n",
    "If you want to run this exercise at home you can download the data at https://desycloud.desy.de/index.php/s/llbX3zpLhazgPJ6 (1.6 GB).\n",
    "\n",
    "If you run this notebook at the CIP pool, during the course the data can be found at `/large_tmp/LMU_DA_ML/top_tagging` - otherwise adjust the following path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/large_tmp/LMU_DA_ML/top_tagging\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The dataset contains about 1M training examples. For now we will just use 100k for training and testing and 10k for validation during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n_examples = 100000\n",
    "df_train = pd.read_hdf(os.path.join(data_dir, \"train.h5\"), \"table\", stop=n_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains the Lorentz Vectors $(E, p_x, p_y, p_z)$ for the leading 200 constituents of the jets. The field `is_signal_new` flags whether the jet is a QCD jet (0) or a Top quark jet (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Since our jets are already clustered with a fixed radius parameter it is convenient to transform the coordinates such that the leading constituent is in the center of the image. As azimuthal and longitudinal coordinates we use the angle $\\phi$ and the [pseudorapidity](https://en.wikipedia.org/wiki/Pseudorapidity) $\\eta$, a quantity where differences are invariant under boost in beam direction. The images will be created by summing (histogramming) transverse momentum values into 40x40 pixels and normalize by the leading constituents transverse momentum (center of the image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_rel(df):\n",
    "    \"\"\"\n",
    "    Create dataframe with PT, ETA, PHI in coordinates relative to leading constituent\n",
    "    \"\"\"\n",
    "\n",
    "    # make new df with relative coordinates (to leading constituent)\n",
    "    # first, just copy the labels for convenience\n",
    "    df_rel = df[[\"is_signal_new\"]].copy()\n",
    "\n",
    "    # Augment with pt, eta, phi\n",
    "    for i in range(200):\n",
    "        df_rel[\"PT_{}\".format(i)] = np.sqrt(df[\"PX_{}\".format(i)]**2 + df[\"PY_{}\".format(i)]**2)\n",
    "        df_rel[\"ETA_{}\".format(i)] = np.arcsinh(df[\"PZ_{}\".format(i)]/df_rel[\"PT_{}\".format(i)])\n",
    "        df_rel[\"PHI_{}\".format(i)] = np.arcsin(df[\"PY_{}\".format(i)]/df_rel[\"PT_{}\".format(i)])\n",
    "\n",
    "    PT_0 = df_rel.PT_0.copy()\n",
    "    ETA_0 = df_rel.ETA_0.copy()\n",
    "    PHI_0 = df_rel.PHI_0.copy()\n",
    "    for i in range(200):\n",
    "        # normalize by leading constituent\n",
    "        df_rel[\"PT_{}\".format(i)] = df_rel[\"PT_{}\".format(i)] / PT_0\n",
    "        \n",
    "        # shift coordinates\n",
    "        df_rel[\"ETA_{}\".format(i)] = df_rel[\"ETA_{}\".format(i)] - ETA_0\n",
    "        df_rel[\"PHI_{}\".format(i)] = df_rel[\"PHI_{}\".format(i)] - PHI_0\n",
    "\n",
    "    df_rel.fillna(0, inplace=True)\n",
    "    return df_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rel_train = get_df_rel(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rel_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does an average jet image look like now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg(df, label=1):\n",
    "    \n",
    "    columns = sum([[\"PT_{}\".format(i), \"ETA_{}\".format(i), \"PHI_{}\".format(i)] for i in range(200)], [])\n",
    "\n",
    "    # transform to reshaped numpy array of particles (irrespective of event)\n",
    "    trf = df[df[\"is_signal_new\"]==label][columns].values.reshape(-1, 3)\n",
    "    pt = trf[:,0]\n",
    "    eta = trf[:,1]\n",
    "    phi = trf[:,2]\n",
    "\n",
    "    plt.hist2d(\n",
    "        eta, phi, bins=(40, 40), range=([-1, 1], [-1, 1]),\n",
    "        # the pixel intensity is the transverse momentum, so we have to weight by pt here\n",
    "        weights=pt,\n",
    "        norm=matplotlib.colors.LogNorm(),\n",
    "    )\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"eta\")\n",
    "    plt.ylabel(\"phi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average QCD jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg(df_rel_train, label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Top quark jet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avg(df_rel_train, label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training a CNN we now have to make an array of these images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_array(df):\n",
    "    \"\"\"\n",
    "    Pixelate constituent arrays per jet\n",
    "    \"\"\"\n",
    "    columns = sum([[\"PT_{}\".format(i), \"ETA_{}\".format(i), \"PHI_{}\".format(i)] for i in range(200)], [])\n",
    "    hists = []\n",
    "    trf = df[columns].values.reshape(-1, 200, 3)\n",
    "    for i in range(len(trf)):\n",
    "        pt = trf[i][:,0]\n",
    "        eta = trf[i][:,1]\n",
    "        phi = trf[i][:,2]\n",
    "        # remember: the pixel intensity is the transverse momentum, so we have to weight by pt here\n",
    "        hist, xedges, yedges = np.histogram2d(eta, phi, bins=(40, 40), range=([-1, 1], [-1, 1]), weights=pt)\n",
    "        hists.append(np.array([hist]))\n",
    "    return np.stack(hists).reshape(-1, 40, 40, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = get_img_array(df_rel_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_rel_train.is_signal_new.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the mean value of these arrays again to check if everything worked as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[y_train==0].mean(axis=0), norm=matplotlib.colors.LogNorm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[y_train==1].mean(axis=0), norm=matplotlib.colors.LogNorm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, preprocess the validation and testing dataset as well. To save a bit of memory, iterate over the initial dataframe in chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df_path, n_examples=100000, chunksize=10000):\n",
    "    x = []\n",
    "    y = []\n",
    "    for start in range(0, n_examples, chunksize):\n",
    "        df = pd.read_hdf(df_path, \"table\", start=start, stop=start + chunksize)\n",
    "        df_rel = get_df_rel(df)\n",
    "        x.append(get_img_array(df_rel))\n",
    "        y.append(df_rel.is_signal_new.values)\n",
    "    return np.concatenate(x), np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = preprocess(os.path.join(data_dir, \"test.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = preprocess(os.path.join(data_dir, \"val.h5\"), n_examples=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the files we put into the git repository, we also converted the color values to unsigned 8bit integers (values between 0 and 255).\n",
    "\n",
    "To loose as little information a possible by this, let's first do a logarithmic transformation. Let's use a small subset for experimentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(np.log(x).ravel(), bins=300, range=(-10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The peak at 0 (1 in the untransformed case) comes from the fact that we normalized our transverse momenta to be relative to the leading constituent for each jet.\n",
    "\n",
    "To convert to unsigned 8bit integers, we map the range `(-10, 5)` to `(1, 255)` and set the `-np.inf` values (resulting from `np.log(0)`) to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x, range=(-10, 5)):\n",
    "    map_1_255 = ((np.log(x) - range[0]) / (range[1] - range[0]) * 255 + 1)\n",
    "    return np.where(x != 0, map_1_255, 0).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(transform(x).ravel(), range=(1, 255), bins=254)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform this back later we will need to reverse that transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_transform(x_uint8, range=(-10, 5)):\n",
    "    reverse_map_1_255 =  np.exp((x_uint8 - 1) / 255 * (range[1] - range[0]) + range[0])\n",
    "    return np.where(x_uint8 != 0, reverse_map_1_255, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x.mean(axis=0), norm=matplotlib.colors.LogNorm())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that there is some information loss for very high values, where the 8bit unsigned int values get a bit more discrete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = dict(bins=200, alpha=0.5, range=(0, 5))\n",
    "plt.hist(x.ravel(), **opts)\n",
    "plt.hist((reverse_transform(transform(x))).ravel(), **opts)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is less visible in a more coarse binning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = dict(bins=30, alpha=0.5, range=(0, 5))\n",
    "plt.hist(x.ravel(), **opts)\n",
    "plt.hist((reverse_transform(transform(x))).ravel(), **opts)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally save them in a compressed format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\n",
    "    \"top_tagging_images.npz\",\n",
    "    x_train=transform(x_train),\n",
    "    y_train=y_train,\n",
    "    x_test=transform(x_test),\n",
    "    y_test=y_test,\n",
    "    x_val=transform(x_val),\n",
    "    y_val=y_val\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "name": "CNNTopTagging.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}