{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB and Missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the usual setup: \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "df = pd.read_csv('data/atlas-higgs-challenge-2014-v2.csv.gz')\n",
    "# map y values to integers\n",
    "df['Label'] = df['Label'].map({'b':0, 's':1});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create separate arrays for ML models\n",
    "eventID = df['EventId']\n",
    "X = df.loc[:,'DER_mass_MMC':'PRI_jet_all_pt']\n",
    "y = df['Label']\n",
    "weight = df['Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now split data and weights into testing and training samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, eventID_train, event_ID_test, weight_train, weight_test = train_test_split(\n",
    "    X, y, eventID, weight, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifiers are built on Bayesian classification methods.\n",
    "Use Bayesâ€™s theorem:\n",
    "$$P(B|A)P(A) = P(A|B)P(B)$$\n",
    "to write\n",
    "$$\n",
    "P(L|\\text{features}) = \\frac{ P(\\text{features}|L) P(L) }{ P(\\text{features}) }\n",
    "$$\n",
    "where \"L\" is the label.\n",
    "\n",
    "From this the ratio of the probability of two labels of a sample given the features can be computed as:\n",
    "$$\n",
    "\\frac{ P(L_1|\\text{features}) }{ P(L_2|\\text{features}) } = \\frac{ P(\\text{features}|L_1)P(L_1) }{ P(\\text{features}|L_2)P(L_2) }\n",
    "$$\n",
    "(Note that $P(\\text{features})$, i.e. the probability distribution of the features, cancels out.)\n",
    "\n",
    "In the Gaussian Naive Bayes classifier, the assumption is that data from each label is drawn from a simple Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GaussianNB (Gaussian Naive Bayes, assumes each class is drawn from an axis-aligned Gaussian distribution)\n",
    "from sklearn.naive_bayes import GaussianNB # 1. choose model class\n",
    "model = GaussianNB()                       # 2. instantiate model\n",
    "model.fit(X_train, y_train);               # 3. fit model to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to plot probability for sig/bg\n",
    "def plot_proba( df, model, x ):\n",
    "    df['Prob']=model.predict_proba(x)[:, 1]\n",
    "    kwargs = dict(histtype='stepfilled', alpha=0.3, bins=40, density=True)\n",
    "    df[df.Label==0].Prob.hist(label='Background',**kwargs)\n",
    "    df[df.Label==1].Prob.hist(label='Signal',**kwargs)\n",
    "    _=plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_proba(df, model, X)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpars0 = pd.DataFrame({\"mean\": model.theta_[0,:], \"sigma\": np.sqrt(model.sigma_[0,:])}, index = X.keys())\n",
    "modelpars1 = pd.DataFrame({\"mean\": model.theta_[1,:], \"sigma\": np.sqrt(model.sigma_[1,:])}, index = X.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the fits done by GaussianNB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def plot(featurepars, data, color):\n",
    "    xmin = featurepars[\"mean\"] - 3*featurepars[\"sigma\"]\n",
    "    xmax = featurepars[\"mean\"] + 3*featurepars[\"sigma\"]\n",
    "    ax.hist(data, bins = 100, range = (xmin, xmax), color = color, alpha = 0.3);\n",
    "    x = np.linspace(xmin, xmax, 100)\n",
    "    ax.plot(x, \n",
    "            stats.norm.pdf(x, featurepars[\"mean\"], featurepars[\"sigma\"])*len(data)/100*(xmax - xmin), \n",
    "            color = color)\n",
    "    \n",
    "fig, axes = plt.subplots(5, 5, figsize=(18, 16))\n",
    "for idx, ax in enumerate(axes.ravel()):\n",
    "    var = X.keys()[idx]\n",
    "    ax.set_xlabel(var)\n",
    "    # plot signal\n",
    "    plot(modelpars1.loc[var], X[y == 1][var], \"g\")\n",
    "    # plot background\n",
    "    plot(modelpars0.loc[var], X[y == 0][var], \"r\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (re-)compute cross-validation score on original model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(GaussianNB(), X, y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = X.where(X != -999, 0) # -999 -> 0\n",
    "# retrain model and determine score (should slightly improve)\n",
    "print(\"Strategy '%s' yields a score of %.4f\" % (\"constant\", cross_val_score(GaussianNB(), X2, y).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace placeholder values (-999.)\n",
    "#X = X.where(X != -999, np.nan) # -999 -> NaN\n",
    "from sklearn.preprocessing import Imputer\n",
    "for strategy in [\"mean\", \"median\", \"most_frequent\"]:\n",
    "    imp = Imputer(missing_values = -999, strategy = strategy)\n",
    "    X2 = imp.fit_transform(X)\n",
    "    # retrain model and determine score (should slightly improve)\n",
    "    print(\"Strategy '%s' yields a score of %.4f\" % (strategy, cross_val_score(GaussianNB(), X2, y).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
